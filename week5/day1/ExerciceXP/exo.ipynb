{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc230654",
   "metadata": {},
   "source": [
    "\n",
    "Exercises XP\n",
    "\n",
    "Last Updated: June 20th, 2025\n",
    "\n",
    "üë©‚Äçüè´ üë©üèø‚Äçüè´ What You'll learn\n",
    "\n",
    "    The fundamentals of deep learning and neural networks.\n",
    "    How to build and train simple neural networks using TensorFlow/Keras.\n",
    "    The concepts of forward and backward propagation.\n",
    "    How to visualize and interpret model predictions.\n",
    "\n",
    "\n",
    "üõ†Ô∏è What you will create\n",
    "\n",
    "    A simple perceptron-based decision system.\n",
    "    A neural network for classifying handwritten digits from the MNIST dataset.\n",
    "    A forward propagation calculation for predicting house prices.\n",
    "    A Python implementation of forward and backward propagation.\n",
    "    Visualizations of predictions made by a neural network on the MNIST dataset.\n",
    "\n",
    "\n",
    "üåü Exercise 1 : Small Quizz\n",
    "\n",
    "    What is the key difference between traditional machine learning and deep learning?\n",
    "    How do artificial neural networks (ANNs) mimic the human brain?\n",
    "    Why does deep learning perform better on large datasets compared to traditional machine learning?\n",
    "    What are some challenges of deep learning, and how can they be addressed?\n",
    "    What is feature engineering, and why is it not needed in deep learning?\n",
    "    What role do hidden layers play in a deep learning model?\n",
    "    In an artificial neural network (ANN), what is the function of an activation function?\n",
    "\n",
    "\n",
    "üåü Exercise 2 : Building a Simple Perceptron Decision System\n",
    "\n",
    "You will manually create a simple perceptron-based decision system to determine whether you should go outside based on two inputs:\n",
    "\n",
    "    Temperature (¬∞F)\n",
    "    Rainy (Yes = 1, No = 0)\n",
    "\n",
    "You will assign weights, compute the weighted sum, apply an activation function, and determine the final decision.\n",
    "\n",
    "    Temperature weight = 0.6\n",
    "    Rain weight = 0.4\n",
    "    Bias = 2\n",
    "\n",
    "Compute the weighted sum using the formula:\n",
    "\n",
    "    Weighted Sum=(Temperature√ó0.6)+(Rain√ó0.4)+Bias\n",
    "    Weighted Sum=(Temperature√ó0.6)+(Rain√ó0.4)+Bias\n",
    "\n",
    "Apply a Step Activation Function:\n",
    "\n",
    "    If Weighted Sum > 20, output 1 (Yes, go outside)\n",
    "    If Weighted Sum ‚â§ 20, output 0 (No, stay inside)\n",
    "\n",
    "1. Calculate the output for the following conditions:\n",
    "\n",
    "    Case 1: Temperature = 70¬∞F, Rain = 0 (No)\n",
    "    Case 2: Temperature = 50¬∞F, Rain = 1 (Yes)\n",
    "\n",
    "2. Interpret the results: Did the perceptron suggest going outside in both cases? Why or why not?\n",
    "\n",
    "\n",
    "üåü Exercise 3 : Building a Simple Neural Network with TensorFlow/Keras\n",
    "\n",
    "Build a simple neural network using TensorFlow/Keras to classify handwritten digits from the MNIST dataset. The network should have:\n",
    "\n",
    "    One input layer.\n",
    "    One hidden layer with 128 neurons and ReLU activation.\n",
    "    One output layer with 10 neurons (for 10 classes) and softmax activation.\n",
    "\n",
    "Steps:\n",
    "\n",
    "1. Import TensorFlow and other necessary modules such as layers, models, and utility functions from tensorflow.keras\n",
    "2. Load the MNIST Dataset\n",
    "3. Normalize the Data by scaling the pixel values of the images to the range [0, 1] by dividing by 255.0.\n",
    "4. One-Hot Encode the Labels by converting the digit labels (0‚Äì9) into one-hot encoded vectors.\n",
    "5. To build the Neural Network Model, create a sequential model with the following architecture:\n",
    "\n",
    "    A Flatten layer to convert each 28x28 image into a 1D vector.\n",
    "    A Dense hidden layer with 128 neurons and ReLU activation.\n",
    "    An output Dense layer with 10 neurons and softmax activation (for the 10 classes).\n",
    "\n",
    "6. Compile the model with the following settings:\n",
    "\n",
    "    Optimizer: ‚Äòadam'\n",
    "    Loss function: ‚Äòcategorical_crossentropy'\n",
    "    Metrics: [‚Äòaccuracy']\n",
    "\n",
    "7. Train the Model and Evaluate it on the test dataset.\n",
    "\n",
    "Dataset: The MNIST dataset is included in TensorFlow/Keras and can be loaded using:\n",
    "\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "\n",
    "üåü Exercise 4 : Forward Propagation Calculation\n",
    "\n",
    "In this exercise, you will manually compute the forward propagation of a simple neural network that predicts house prices based on:\n",
    "\n",
    "    Square Footage (x‚ÇÅ)\n",
    "    Number of Bedrooms (x‚ÇÇ)\n",
    "\n",
    "We will calculate the output using the following given values:\n",
    "\n",
    "Input Values:\n",
    "    x‚ÇÅ = 2000 (Square Footage)\n",
    "    x‚ÇÇ = 3 (Number of Bedrooms)\n",
    "Initial Weights:\n",
    "    w‚ÇÅ = 0.5 (Weight for Square Footage)\n",
    "    w‚ÇÇ = 0.7 (Weight for Bedrooms)\n",
    "Bias: b = 50,000\n",
    "Activation Function: ReLU (Rectified Linear Unit)\n",
    "\n",
    "    Calculate the output value \"z\" before activation.\n",
    "    Apply the ReLU function to compute the final prediction.\n",
    "    Interpret the result: What is the predicted house price?\n",
    "\n",
    "\n",
    "üåü Exercise 5(optional) : Implementing Forward and Backward Propagation in Python\n",
    "\n",
    "You will code a simple neural network that performs forward propagation and backpropagation for a regression problem (predicting exam scores based on study hours).\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Initialize input data (features)\n",
    "x = np.array([4, 80])  # 4 hours studied, previous test score: 80\n",
    "\n",
    "# Initialize weights and bias\n",
    "w = np.array([0.6, 0.3])  # Initial weights\n",
    "b = 10  # Initial bias\n",
    "\n",
    "# Forward Propagation\n",
    "def forward_propagation(x, w, b):\n",
    "    z = np.dot(x, w) + b  # Weighted sum\n",
    "    return z  # Linear activation (No ReLU here, it's a regression task)\n",
    "\n",
    "# Compute prediction\n",
    "y_pred = forward_propagation(x, w, b)\n",
    "y_true = 85  # Actual exam score\n",
    "\n",
    "# Compute Loss (Mean Squared Error)\n",
    "loss = 0.5 * (y_true - y_pred) ** 2\n",
    "\n",
    "# Compute Gradients\n",
    "grad_w = -(y_true - y_pred) * x  # Partial derivatives with respect to weights\n",
    "grad_b = -(y_true - y_pred)  # Partial derivative with respect to bias\n",
    "\n",
    "# Update Weights and Bias\n",
    "learning_rate = 0.01\n",
    "w_new = w - learning_rate * grad_w\n",
    "b_new = b - learning_rate * grad_b\n",
    "\n",
    "# Print Results\n",
    "print(\"Initial Prediction:\", y_pred)\n",
    "print(\"Loss:\", loss)\n",
    "print(\"Updated Weights:\", w_new)\n",
    "print(\"Updated Bias:\", b_new)\n",
    "\n",
    "\n",
    "    Run the code and observe how the weights and bias update.\n",
    "    Explain why updating weights using gradient descent reduces the error.\n",
    "    Modify the initial weights or learning rate and see how it affects learning.\n",
    "\n",
    "\n",
    "üåü Exercise 6(optional) : Visualizing Predictions on the MNIST Dataset\n",
    "\n",
    "Train a simple neural network using TensorFlow/Keras on the MNIST dataset. After training, visualize some of the predictions made by the model.\n",
    "\n",
    "Dataset: The MNIST dataset is included in TensorFlow/Keras.\n",
    "\n",
    "Here are the steps for this exercise :\n",
    "\n",
    "0. Import Required Libraries : Import TensorFlow, NumPy, Matplotlib, and other necessary Keras modules.\n",
    "1. Load the MNIST dataset\n",
    "2. Normalize the data : Scale the pixel values to the range [0, 1].\n",
    "3. One-hot encode the labels : Convert the class labels (digits 0‚Äì9) into one-hot encoded vectors.\n",
    "4. Build the model : Create a model with a Flatten layer to convert each image to a vector, a dense layer with 128 neurons and ReLU activation and an output Dense layer with 10 neurons and softmax activation.\n",
    "5. Compile the model using the following settings:\n",
    "\n",
    "    Optimizer: ‚Äòadam'\n",
    "    Loss: ‚Äòcategorical_crossentropy'\n",
    "    Metric: ‚Äòaccuracy'\n",
    "\n",
    "6. Fit the model on the training data\n",
    "7. Make predictions : Use the trained model to predict the labels of the test images\n",
    "8. Visualize some predictions : Display a few test images alongside the predicted labels using Matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c6c2539",
   "metadata": {},
   "source": [
    "Diff√©rence cl√© entre ML traditionnel et Deep Learning ?\n",
    "-> Le Machine Learning repose souvent sur des features extraites manuellement, tandis que le Deep Learning apprend automatiquement les bonnes repr√©sentations √† partir des donn√©es brutes gr√¢ce √† ses couches profondes.\n",
    "\n",
    "Comment les r√©seaux de neurones imitent-ils le cerveau ?\n",
    "-> Ils sont inspir√©s des neurones biologiques : chaque \"neurone\" artificiel re√ßoit des signaux, les pond√®re, les additionne et transmet un signal si un certain seuil est d√©pass√©.\n",
    "\n",
    "Pourquoi le Deep Learning est-il meilleur avec de grands datasets ?\n",
    "-> Parce qu'il a beaucoup de param√®tres √† apprendre. Il g√©n√©ralise mieux si les donn√©es sont nombreuses et vari√©es.\n",
    "\n",
    "D√©fis du Deep Learning ? Solutions ?\n",
    "\n",
    "    Donn√©es insuffisantes -> Data augmentation, pr√©-entra√Ænement\n",
    "\n",
    "    Overfitting -> Dropout, r√©gularisation\n",
    "\n",
    "    Co√ªt -> GPU/TPU, mod√®les plus petits\n",
    "\n",
    "Feature engineering : pourquoi moins utile ?\n",
    "-> Car un r√©seau profond apprend automatiquement des repr√©sentations hi√©rarchiques. Tu n'as plus besoin de d√©cider \"quelle variable utiliser\".\n",
    "\n",
    "R√¥le des couches cach√©es ?\n",
    "-> Ce sont elles qui apprennent les repr√©sentations interm√©diaires. Chaque couche extrait des patterns de plus haut niveau.\n",
    "\n",
    "R√¥le de la fonction d'activation ?\n",
    "-> Elle introduit de la non-lin√©arit√©, essentielle pour apprendre des fonctions complexes. Sans √ßa, le r√©seau ne ferait que des combinaisons lin√©aires."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a06ecdb5",
   "metadata": {},
   "source": [
    "Exercice 2 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6b0483",
   "metadata": {},
   "source": [
    "On applique la formule : weighted_sum = (temperature * 0.6) + (rain * 0.4) + 2\n",
    "\n",
    "1 : Temp = 70¬∞F, Rain = 0\n",
    "(70 * 0.6) + (0 * 0.4) + 2 = 42 + 0 + 2 = 44 -> > 20 -> Go Outside (1)\n",
    "\n",
    "2 : Temp = 50¬∞F, Rain = 1\n",
    "(50 * 0.6) + (1 * 0.4) + 2 = 30 + 0.4 + 2 = 32.4 -> > 20 -> Go Outside (1)\n",
    "\n",
    "les deux cas donnent une sortie positive.\n",
    "La temp√©rature a un poids tr√®s fort."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bffca84",
   "metadata": {},
   "source": [
    "Exercice 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ce00034",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mathi\\Downloads\\GenAI\\GenAI_Bootcamp\\tf_env\\lib\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1500/1500\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.8717 - loss: 0.4682 - val_accuracy: 0.9567 - val_loss: 0.1546\n",
      "Epoch 2/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 953us/step - accuracy: 0.9602 - loss: 0.1381 - val_accuracy: 0.9672 - val_loss: 0.1142\n",
      "Epoch 3/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 921us/step - accuracy: 0.9740 - loss: 0.0881 - val_accuracy: 0.9663 - val_loss: 0.1126\n",
      "Epoch 4/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 952us/step - accuracy: 0.9810 - loss: 0.0635 - val_accuracy: 0.9730 - val_loss: 0.0906\n",
      "Epoch 5/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 984us/step - accuracy: 0.9851 - loss: 0.0482 - val_accuracy: 0.9730 - val_loss: 0.0904\n",
      "Epoch 6/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 958us/step - accuracy: 0.9884 - loss: 0.0385 - val_accuracy: 0.9728 - val_loss: 0.0931\n",
      "Epoch 7/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 943us/step - accuracy: 0.9926 - loss: 0.0270 - val_accuracy: 0.9767 - val_loss: 0.0865\n",
      "Epoch 8/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9933 - loss: 0.0217 - val_accuracy: 0.9737 - val_loss: 0.0965\n",
      "Epoch 9/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9956 - loss: 0.0163 - val_accuracy: 0.9775 - val_loss: 0.0876\n",
      "Epoch 10/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9963 - loss: 0.0143 - val_accuracy: 0.9760 - val_loss: 0.0932\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 802us/step - accuracy: 0.9742 - loss: 0.0936\n",
      "Accuracy sur test : 0.9772999882698059\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.datasets import mnist\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# 1. Charger les donn√©es\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# 2. Normalisation\n",
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0\n",
    "\n",
    "# 3. Encodage des labels\n",
    "y_train = to_categorical(y_train, 10)\n",
    "y_test = to_categorical(y_test, 10)\n",
    "\n",
    "# 4. Cr√©ation du mod√®le\n",
    "model = models.Sequential([\n",
    "    layers.Flatten(input_shape=(28, 28)),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# 5. Compilation\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# 6. Entra√Ænement\n",
    "history = model.fit(x_train, y_train, epochs=10, validation_split=0.2)\n",
    "\n",
    "# 7. √âvaluation\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "print(\"Accuracy sur test :\", test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4967945",
   "metadata": {},
   "source": [
    "Exercice 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ef695a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#z = x1*w1 + x2*w2 + b\n",
    "\n",
    "x1 = 2000\n",
    "\n",
    "x2 = 3\n",
    "\n",
    "w1 = 0.5\n",
    "\n",
    "w2 = 0.7\n",
    "\n",
    "b = 50,000\n",
    "\n",
    "z = (2000 * 0.5) + (3 * 0.7) + 50000 = 1000 + 2.1 + 50000 = 51002.1\n",
    "\n",
    "max(0, 51002.1) = 51002.1\n",
    "\n",
    "#Pr√©diction du prix : 51‚ÄØ002 $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba9137c",
   "metadata": {},
   "source": [
    "Exercice 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f759e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Donn√©es\n",
    "x = np.array([4, 80])\n",
    "w = np.array([0.6, 0.3])\n",
    "b = 10\n",
    "y_true = 85\n",
    "\n",
    "# Forward\n",
    "y_pred = np.dot(x, w) + b\n",
    "\n",
    "# Loss\n",
    "loss = 0.5 * (y_true - y_pred) ** 2\n",
    "\n",
    "# Gradients\n",
    "grad_w = -(y_true - y_pred) * x\n",
    "grad_b = -(y_true - y_pred)\n",
    "\n",
    "# Update\n",
    "lr = 0.01\n",
    "w -= lr * grad_w\n",
    "b -= lr * grad_b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce0dff5",
   "metadata": {},
   "source": [
    " La descente de gradient ajuste les poids pour r√©duire l‚Äôerreur √† chaque it√©ration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f893f1d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 671us/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Pr√©dictions\n",
    "predictions = model.predict(x_test)\n",
    "\n",
    "# Visualisation\n",
    "plt.figure(figsize=(10, 5))\n",
    "for i in range(10):\n",
    "    plt.subplot(2, 5, i + 1)\n",
    "    plt.imshow(x_test[i], cmap='gray')\n",
    "    plt.title(f\"Pred: {np.argmax(predictions[i])}\")\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
