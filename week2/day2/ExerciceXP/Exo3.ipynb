{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8292e70e",
   "metadata": {},
   "source": [
    "\n",
    "Exercises XP Ninja\n",
    "\n",
    "Last Updated: October 16th, 2024\n",
    "\n",
    "üë©‚Äçüè´ üë©üèø‚Äçüè´ What You'll learn\n",
    "\n",
    "    Practice converting unstructured data into a structured format.\n",
    "    Conducting a basic analysis of a dataset\n",
    "    Gain knowledge of various tools and techniques for processing both structured and unstructured data, including sentiment analysis.\n",
    "\n",
    "\n",
    "üõ†Ô∏è What you will create\n",
    "\n",
    "    Transform an unstructured dataset into a structured format, creating a new, organized dataset.\n",
    "    Create reports that detail the analysis of both a structured and an unstructured dataset, highlighting key findings.\n",
    "\n",
    "\n",
    "Exercise 1 : Comparative Analysis of Structured and Unstructured Data\n",
    "\n",
    "    Given two datasets - one structured, a CSV file of product sales data and one unstructured, a collection of customer support tickets, perform a basic analysis on each.\n",
    "    Identify the challenges faced while processing the unstructured dataset as compared to the structured dataset.\n",
    "    Describe the tools and techniques that were effective for each type of data.\n",
    "\n",
    "Hint: Sentiment Analysis using TextBlob\n",
    "\n",
    "\n",
    "Exercise 2 : Converting Unstructured Data to Structured Data\n",
    "\n",
    "Here is an unstructured dataset containing tweets.\n",
    "\n",
    "    Apply text processing techniques to extract key information (such as hashtags and mentions, you already have a column ‚Äúsentiment‚Äù) from the dataset.\n",
    "    Organize this extracted information into a structured format (like a table with columns for each key information type).\n",
    "    Perform a basic analysis on the newly structured data and compare insights with the original unstructured format.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea32134",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from textblob import TextBlob\n",
    "\n",
    "# Chargement\n",
    "sales_df = pd.read_csv(\"statsfinal.csv\")\n",
    "tickets_df = pd.read_csv(\"customer_support_tickets.csv\")\n",
    "\n",
    "# Analyse structuree\n",
    "print(\"Colonnes ventes :\", sales_df.columns)\n",
    "print(\"Moyenne Q-P1 :\", sales_df['Q-P1'].mean())\n",
    "\n",
    "# Analyse non structuree\n",
    "def get_sentiment(text):\n",
    "    return TextBlob(text).sentiment.polarity\n",
    "\n",
    "tickets_df['sentiment'] = tickets_df['Ticket Description'].apply(lambda x: get_sentiment(str(x)))\n",
    "print(\"Sentiment moyen :\", tickets_df['sentiment'].mean())\n",
    "\n",
    "# Analyse parpriorite\n",
    "print(tickets_df.groupby(\"Ticket Priority\")[\"sentiment\"].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ddb6df",
   "metadata": {},
   "source": [
    "J'ai charge les fichiers suivants :\n",
    "\n",
    "    statsfinal.csv : fichier structure contenant les donnees de vente produit.\n",
    "\n",
    "    customer_support_tickets.csv : fichier non structure contenant des tickets de support client.\n",
    "\n",
    "Voici un apercu des premieres lignes :\n",
    "\n",
    "Fichier structure (ventes) :\n",
    "\n",
    "    Colonnes presentes : Date, Q-P1, Q-P2, Q-P3, Q-P4, S-P1, S-P2, S-P3, S-P4\n",
    "\n",
    "    Total : 10 colonnes (dont 4 de quantite, 4 de chiffre d'affaires)\n",
    "\n",
    "    Donnees bien structurees, formats numeriques et dates, facilement utilisables\n",
    "\n",
    "Fichier non structure (tickets support) :\n",
    "\n",
    "    Colonnes presentes : Ticket ID, Nom, Email, Produit, Sujet, Description, etc.\n",
    "\n",
    "    Total : 17 colonnes\n",
    "\n",
    "    Champ Ticket Description : texte libre non structure\n",
    "\n",
    "    Plusieurs valeurs manquantes (Resolution, Satisfaction, etc.)\n",
    "\n",
    "Donnees structurees :\n",
    "\n",
    "    statsfinal.csv : toutes les donnees sont structurees (numeriques, dates)\n",
    "\n",
    "    Utilisables directement avec Pandas pour des calculs et des graphiques\n",
    "\n",
    "Donnees non structurees :\n",
    "\n",
    "    customer_support_tickets.csv :\n",
    "\n",
    "        Le champ Ticket Description est du texte libre\n",
    "\n",
    "        Doit etre nettoye et transforme pour pouvoir l'analyser (tokenisation, sentiment, etc.)\n",
    "\n",
    "        Beaucoup plus de colonnes et de variabilite\n",
    "\n",
    "Difficultees avec le dataset non structure :\n",
    "\n",
    "    Le texte n'est pas exploitable tel quel : il faut nettoyer, tokeniser, traiter les mots\n",
    "\n",
    "    Les donnees manquantes rendent l'analyse partielle\n",
    "\n",
    "    Certains champs sont vagues ou ambigus (subjectifs, ouverts)\n",
    "\n",
    "Outils et techniques efficaces :\n",
    "\n",
    "    Pour les donnees structurees :\n",
    "\n",
    "        Pandas (regroupement, moyenne, somme‚Ä¶)\n",
    "\n",
    "        Visualisation simple avec matplotlib ou seaborn\n",
    "\n",
    "    Pour les donnees non structurees :\n",
    "\n",
    "        TextBlob pour l'analyse de sentiment\n",
    "\n",
    "        Regex pour extraire des motifs\n",
    "\n",
    "        Preprocessing (minuscules, suppression ponctuation, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f6081c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# charger les tweets\n",
    "df = pd.read_csv(\"Tweets.csv\")\n",
    "print(df.head(3))  # voir les colonnes\n",
    "\n",
    "# fonction pour extraire hashtags\n",
    "def extract_hashtags(text):\n",
    "    return re.findall(r\"#(\\w+)\", str(text))\n",
    "\n",
    "# fonction pour extraire mentions\n",
    "def extract_mentions(text):\n",
    "    return re.findall(r\"@(\\w+)\", str(text))\n",
    "\n",
    "# ajouter colonnes structurees\n",
    "df[\"hashtags\"] = df[\"text\"].apply(extract_hashtags)\n",
    "df[\"mentions\"] = df[\"text\"].apply(extract_mentions)\n",
    "\n",
    "# afficher les colonnes cle\n",
    "print(df[[\"text\", \"sentiment\", \"hashtags\", \"mentions\"]].head(5))\n",
    "\n",
    "# compter nombre de tweets par sentiment\n",
    "print(df[\"sentiment\"].value_counts())\n",
    "\n",
    "# analyser les hashtags les plus frequents\n",
    "all_hashtags = sum(df[\"hashtags\"], [])\n",
    "hashtags_freq = pd.Series(all_hashtags).value_counts()\n",
    "print(hashtags_freq.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc3fc868",
   "metadata": {},
   "source": [
    "Analyse structuree\n",
    "\n",
    "    colonnes text et sentiment deja presentes\n",
    "\n",
    "    ajout de :\n",
    "\n",
    "        hashtags = liste des hashtags par tweet\n",
    "\n",
    "        mentions = liste des @utilisateurs\n",
    "\n",
    "donnees structurees :\n",
    "\n",
    "    sentiment : 3 categories fixes\n",
    "\n",
    "    hashtags : extraits et comptables\n",
    "\n",
    "    mentions : identifiables\n",
    "\n",
    "donnees non structurees :\n",
    "\n",
    "    text : brut, avec langage naturel\n",
    "\n",
    "    contient bruit, ironie, emojis, fautes\n",
    "\n",
    "observation\n",
    "\n",
    "    avant : analyse limitee aux sentiments\n",
    "\n",
    "    apres : on peut voir quels hashtags reviennent le + souvent\n",
    "\n",
    "    on peut croiser hashtags + sentiment (ex : \"#support\" est souvent negatif)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
