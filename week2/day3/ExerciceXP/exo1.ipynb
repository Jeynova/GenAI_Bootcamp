{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e91d7755",
   "metadata": {},
   "source": [
    "\n",
    "Exercises XP\n",
    "\n",
    "Last Updated: October 16th, 2024\n",
    "\n",
    "What you will learn\n",
    "\n",
    "    Identify and remove duplicate entries in the Titanic dataset.\n",
    "    Explore various techniques for handling missing values in the Titanic dataset.\n",
    "    Perform feature engineering on the Titanic dataset to create new meaningful attributes.\n",
    "    Standardize and normalize numerical columns in the Titanic dataset for consistent scale.\n",
    "    Transform the Age feature in the Titanic dataset for better representation and analysis.\n",
    "\n",
    "\n",
    "What you will create\n",
    "\n",
    "    A cleaned version of the Titanic dataset with duplicate rows removed.\n",
    "    A version of the Titanic dataset where missing values have been addressed using various strategies like removal, imputation, and constant value filling.\n",
    "    A Titanic dataset with standardized and normalized numerical columns.A Titanic dataset with passengers categorized into different age groups and these groups encoded into binary features.\n",
    "    A Titanic dataset with encoded categorical features using one-hot and label encoding techniques.\n",
    "\n",
    "\n",
    "For all of the below exercises, you will use the Titanic dataset (train.csv), so load it beforehand on your notebook.\n",
    "You will notice in the following exercises that the dataset is already pretty clean but try and understand all of the functions used for preprocessing the data.\n",
    "Optionally, if you have time and willing to, you can redo the exercises with a less clean dataset : Weather Data Munich 1954-2022.\n",
    "ðŸŒŸ Exercise 1: Duplicate Detection and Removal\n",
    "Instructions\n",
    "\n",
    "Objective: Identify and remove duplicate entries in the Titanic dataset.\n",
    "\n",
    "    Load the Titanic dataset.\n",
    "    Identify if there are any duplicate rows based on all columns.\n",
    "    Remove any duplicate rows found in the dataset.\n",
    "    Verify the removal of duplicates by checking the number of rows before and after the duplicate removal.\n",
    "\n",
    "Hint: Use the duplicated() and drop_duplicates() functions in Pandas.\n",
    "\n",
    "\n",
    "ðŸŒŸ Exercise 2: Handling Missing Values\n",
    "Instructions\n",
    "\n",
    "    Identify columns in the Titanic dataset with missing values.\n",
    "    Explore different strategies for handling missing data, such as removal, imputation, and filling with a constant value.\n",
    "    Apply each strategy to different columns based on the nature of the data.\n",
    "\n",
    "Hint: Review methods like dropna(), fillna(), and SimpleImputer from scikit-learn.\n",
    "\n",
    "\n",
    "ðŸŒŸ Exercise 3: Feature Engineering\n",
    "Instructions\n",
    "\n",
    "    Create new features, such as Family Size from SibSp and Parch, and Title extracted from the Name column.\n",
    "    Convert categorical variables into numerical form using techniques like one-hot encoding or label encoding.\n",
    "    Normalize or standardize numerical features if required.\n",
    "\n",
    "Hint: Utilize Pandas for data manipulation and scikit-learnâ€™s preprocessing module for encoding.\n",
    "\n",
    "\n",
    "ðŸŒŸ Exercise 4: Outlier Detection and Handling\n",
    "Instructions\n",
    "\n",
    "    Use statistical methods to detect outliers in columns like Fare and Age.\n",
    "    Decide on a strategy to handle the identified outliers, such as capping, transformation, or removal.\n",
    "    Implement the chosen strategy and assess its impact on the dataset.\n",
    "\n",
    "Hint: Explore methods like IQR (Interquartile Range) and Z-score for outlier detection.\n",
    "\n",
    "\n",
    "ðŸŒŸ Exercise 5: Data Standardization and Normalization\n",
    "Instructions\n",
    "\n",
    "    Assess the scale and distribution of numerical columns in the dataset.\n",
    "    Apply standardization to features with a wide range of values.\n",
    "    Normalize data that requires a bounded range, like [0, 1].\n",
    "\n",
    "Hint: Consider using StandardScaler and MinMaxScaler from scikit-learnâ€™s preprocessing module.\n",
    "\n",
    "\n",
    "ðŸŒŸ Exercise 6: Feature Encoding\n",
    "Instructions\n",
    "\n",
    "    Identify categorical columns in the Titanic dataset, such as Sex and Embarked.\n",
    "    Use one-hot encoding for nominal variables and label encoding for ordinal variables.\n",
    "    Integrate the encoded features back into the main dataset.\n",
    "\n",
    "Hint: Utilize pandas.get_dummies() for one-hot encoding and LabelEncoder from scikit-learn for label encoding.\n",
    "\n",
    "\n",
    "ðŸŒŸ Exercise 7: Data Transformation for Age Feature\n",
    "Instructions\n",
    "\n",
    "    Create age groups (bins) from the Age column to categorize passengers into different age categories.\n",
    "    Apply one-hot encoding to the age groups to convert them into binary features.\n",
    "\n",
    "Hint: Use pd.cut() for binning the Age column and pd.get_dummies() for one-hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "564c68eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c422010c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"train.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e610352",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"taille:\", df.shape)\n",
    "\n",
    "doublons = df.duplicated()\n",
    "\n",
    "print(\"doublons :\", doublons.sum())\n",
    "df_sans_doublons = df.drop_duplicates()\n",
    "print(\"no doublons:\", df_sans_doublons.shape)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d3b59ef6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val manquantes:\n",
      "PassengerId    0\n",
      "Survived       0\n",
      "Pclass         0\n",
      "Name           0\n",
      "Sex            0\n",
      "Age            0\n",
      "SibSp          0\n",
      "Parch          0\n",
      "Ticket         0\n",
      "Fare           0\n",
      "Cabin          0\n",
      "Embarked       0\n",
      "dtype: int64\n",
      "   PassengerId  Survived  Pclass  \\\n",
      "0            1         0       3   \n",
      "1            2         1       1   \n",
      "2            3         1       3   \n",
      "3            4         1       1   \n",
      "4            5         0       3   \n",
      "\n",
      "                                                Name     Sex   Age  SibSp  \\\n",
      "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
      "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
      "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
      "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
      "4                           Allen, Mr. William Henry    male  35.0      0   \n",
      "\n",
      "   Parch            Ticket     Fare Cabin Embarked  \n",
      "0      0         A/5 21171   7.2500     U        S  \n",
      "1      0          PC 17599  71.2833   C85        C  \n",
      "2      0  STON/O2. 3101282   7.9250     U        S  \n",
      "3      0            113803  53.1000  C123        S  \n",
      "4      0            373450   8.0500     U        S  \n"
     ]
    }
   ],
   "source": [
    "df = df.dropna(subset=[\"Embarked\"])\n",
    "\n",
    "median_age = df[\"Age\"].median()\n",
    "df[\"Age\"] = df[\"Age\"].fillna(median_age)\n",
    "df[\"Cabin\"] = df[\"Cabin\"].fillna(\"U\")\n",
    "\n",
    "\"\"\" \n",
    "Embarked = port d'embarquement du passager (C = Cherbourg, Q = Queenstown, S = Southampton)\n",
    "\n",
    "    Il n'y a que 2 valeurs manquantes dans tout le dataset.\n",
    "\n",
    "    On ne peut pas deviner facilement d'oÃ¹ est parti un passager.\n",
    "\n",
    "    suppression car trÃ¨s peu de valeurs manquantes.\n",
    "    \n",
    "remplir les Ã¢ges manquants\n",
    "\n",
    "    Il y a beaucoup de valeurs manquantes.\n",
    "\n",
    "    supprimer = grosse perte d'information.\n",
    "\n",
    "    La mÃ©diane = pas d'influences des outliers.\n",
    "    \n",
    "remplir avec \"U\" (Unknown)\n",
    "\n",
    "    Cabin = beaucoup trop de valeurs manquantes\n",
    "\n",
    "    Ne pas supprimer\n",
    "\n",
    "    estimation impossible ( je crois )\n",
    "\n",
    "    -> On ne connait pas la cabine\n",
    " \"\"\"\n",
    "print(\"val manquantes:\")\n",
    "print(df.isnull().sum())\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8b622e62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PassengerId  Survived  Pclass  \\\n",
      "0            1         0       3   \n",
      "1            2         1       1   \n",
      "2            3         1       3   \n",
      "3            4         1       1   \n",
      "4            5         0       3   \n",
      "\n",
      "                                                Name     Sex   Age  SibSp  \\\n",
      "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
      "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
      "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
      "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
      "4                           Allen, Mr. William Henry    male  35.0      0   \n",
      "\n",
      "   Parch            Ticket     Fare Cabin Embarked  FamilySize Title  \n",
      "0      0         A/5 21171   7.2500     U        S           2    Mr  \n",
      "1      0          PC 17599  71.2833   C85        C           2   Mrs  \n",
      "2      0  STON/O2. 3101282   7.9250     U        S           1  Miss  \n",
      "3      0            113803  53.1000  C123        S           2   Mrs  \n",
      "4      0            373450   8.0500     U        S           1    Mr  \n"
     ]
    }
   ],
   "source": [
    "df[\"FamilySize\"] = df[\"SibSp\"] + df[\"Parch\"] + 1\n",
    "df[\"Title\"] = df[\"Name\"].apply(lambda x: x.split(',')[1].split('.')[0].strip())\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7fa14231",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PassengerId  Survived  Pclass  \\\n",
      "0            1         0       3   \n",
      "1            2         1       1   \n",
      "2            3         1       3   \n",
      "3            4         1       1   \n",
      "4            5         0       3   \n",
      "\n",
      "                                                Name     Sex   Age  SibSp  \\\n",
      "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
      "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
      "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
      "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
      "4                           Allen, Mr. William Henry    male  35.0      0   \n",
      "\n",
      "   Parch            Ticket     Fare  ... Title_Master Title_Miss  Title_Mlle  \\\n",
      "0      0         A/5 21171   7.2500  ...        False      False       False   \n",
      "1      0          PC 17599  71.2833  ...        False      False       False   \n",
      "2      0  STON/O2. 3101282   7.9250  ...        False       True       False   \n",
      "3      0            113803  53.1000  ...        False      False       False   \n",
      "4      0            373450   8.0500  ...        False      False       False   \n",
      "\n",
      "  Title_Mme  Title_Mr  Title_Mrs  Title_Ms  Title_Rev  Title_Sir  \\\n",
      "0     False      True      False     False      False      False   \n",
      "1     False     False       True     False      False      False   \n",
      "2     False     False      False     False      False      False   \n",
      "3     False     False       True     False      False      False   \n",
      "4     False      True      False     False      False      False   \n",
      "\n",
      "   Title_the Countess  \n",
      "0               False  \n",
      "1               False  \n",
      "2               False  \n",
      "3               False  \n",
      "4               False  \n",
      "\n",
      "[5 rows x 35 columns]\n"
     ]
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "df[\"Sex_encoded\"] = le.fit_transform(df[\"Sex\"])\n",
    "\n",
    "\n",
    "embarked_dummies = pd.get_dummies(df[\"Embarked\"], prefix=\"Embarked\")\n",
    "df = pd.concat([df, embarked_dummies], axis=1)\n",
    "\n",
    "\n",
    "title_dummies = pd.get_dummies(df[\"Title\"], prefix=\"Title\")\n",
    "df = pd.concat([df, title_dummies], axis=1)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "789e71b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max Age/Fare apres cap : 64.8125 / 65.6344\n",
      "   PassengerId  Survived  Pclass  \\\n",
      "0            1         0       3   \n",
      "1            2         1       1   \n",
      "2            3         1       3   \n",
      "3            4         1       1   \n",
      "4            5         0       3   \n",
      "\n",
      "                                                Name     Sex   Age  SibSp  \\\n",
      "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
      "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
      "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
      "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
      "4                           Allen, Mr. William Henry    male  35.0      0   \n",
      "\n",
      "   Parch            Ticket     Fare Cabin Embarked  \n",
      "0      0         A/5 21171   7.2500   NaN        S  \n",
      "1      0          PC 17599  65.6344   C85        C  \n",
      "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
      "3      0            113803  53.1000  C123        S  \n",
      "4      0            373450   8.0500   NaN        S  \n",
      "standardisation)\n",
      "normalisation\n",
      "age standardise: [-0.53280867  0.58555349 -0.25321813  0.37586058  0.37586058]\n",
      "age normalise: [0.3351322  0.58360834 0.39725123 0.53701906 0.53701906]\n",
      "   PassengerId  Survived  Pclass  \\\n",
      "0            1         0       3   \n",
      "1            2         1       1   \n",
      "2            3         1       3   \n",
      "3            4         1       1   \n",
      "4            5         0       3   \n",
      "\n",
      "                                                Name     Sex   Age  SibSp  \\\n",
      "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
      "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
      "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
      "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
      "4                           Allen, Mr. William Henry    male  35.0      0   \n",
      "\n",
      "   Parch            Ticket     Fare Cabin Embarked  FamilySize  \n",
      "0      0         A/5 21171   7.2500   NaN        S           2  \n",
      "1      0          PC 17599  65.6344   C85        C           2  \n",
      "2      0  STON/O2. 3101282   7.9250   NaN        S           1  \n",
      "3      0            113803  53.1000  C123        S           2  \n",
      "4      0            373450   8.0500   NaN        S           1  \n"
     ]
    }
   ],
   "source": [
    "def cap_outliers(df, column):\n",
    "    Q1 = df[column].quantile(0.25)\n",
    "    Q3 = df[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower = Q1 - 1.5 * IQR\n",
    "    upper = Q3 + 1.5 * IQR\n",
    "    df[column] = df[column].clip(lower, upper)\n",
    "\n",
    "cap_outliers(df, \"Age\")\n",
    "cap_outliers(df, \"Fare\")\n",
    "print(\"max Age/Fare apres cap :\", df[\"Age\"].max(), \"/\", df[\"Fare\"].max())\n",
    "print(df.head())\n",
    "\n",
    "numeric_cols = [\"Age\", \"Fare\", \"FamilySize\"]\n",
    "df[\"FamilySize\"] = df[\"SibSp\"] + df[\"Parch\"] + 1\n",
    "scaler_std = StandardScaler()\n",
    "df_std = df[numeric_cols].copy()\n",
    "df_std[numeric_cols] = scaler_std.fit_transform(df_std[numeric_cols])\n",
    "print(\"standardisation)\")\n",
    "\n",
    "scaler_norm = MinMaxScaler()\n",
    "df_norm = df[numeric_cols].copy()\n",
    "df_norm[numeric_cols] = scaler_norm.fit_transform(df_norm[numeric_cols])\n",
    "print(\"normalisation\")\n",
    "print(\"age standardise:\", df_std[\"Age\"].head().values)\n",
    "print(\"age normalise:\", df_norm[\"Age\"].head().values)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1bdbc965",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encodage label Sex\n",
      "encodage one-hot de Embarked\n",
      "colonnes ajoutees : ['Sex_encoded', 'Embarked_C', 'Embarked_Q', 'Embarked_S']\n",
      "groupe 'AgeGroup'\n",
      "encodage one-hot AgeGroup\n",
      "colonnes : ['Age_child', 'Age_teen', 'Age_young_adult', 'Age_adult', 'Age_senior']\n",
      "<bound method NDFrame.head of      PassengerId  Survived  Pclass  \\\n",
      "0              1         0       3   \n",
      "1              2         1       1   \n",
      "2              3         1       3   \n",
      "3              4         1       1   \n",
      "4              5         0       3   \n",
      "..           ...       ...     ...   \n",
      "886          887         0       2   \n",
      "887          888         1       1   \n",
      "888          889         0       3   \n",
      "889          890         1       1   \n",
      "890          891         0       3   \n",
      "\n",
      "                                                  Name     Sex   Age  SibSp  \\\n",
      "0                              Braund, Mr. Owen Harris    male  22.0      1   \n",
      "1    Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
      "2                               Heikkinen, Miss. Laina  female  26.0      0   \n",
      "3         Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
      "4                             Allen, Mr. William Henry    male  35.0      0   \n",
      "..                                                 ...     ...   ...    ...   \n",
      "886                              Montvila, Rev. Juozas    male  27.0      0   \n",
      "887                       Graham, Miss. Margaret Edith  female  19.0      0   \n",
      "888           Johnston, Miss. Catherine Helen \"Carrie\"  female   NaN      1   \n",
      "889                              Behr, Mr. Karl Howell    male  26.0      0   \n",
      "890                                Dooley, Mr. Patrick    male  32.0      0   \n",
      "\n",
      "     Parch            Ticket     Fare  ... Sex_encoded Embarked_C  Embarked_Q  \\\n",
      "0        0         A/5 21171   7.2500  ...           1      False       False   \n",
      "1        0          PC 17599  65.6344  ...           0       True       False   \n",
      "2        0  STON/O2. 3101282   7.9250  ...           0      False       False   \n",
      "3        0            113803  53.1000  ...           0      False       False   \n",
      "4        0            373450   8.0500  ...           1      False       False   \n",
      "..     ...               ...      ...  ...         ...        ...         ...   \n",
      "886      0            211536  13.0000  ...           1      False       False   \n",
      "887      0            112053  30.0000  ...           0      False       False   \n",
      "888      2        W./C. 6607  23.4500  ...           0      False       False   \n",
      "889      0            111369  30.0000  ...           1       True       False   \n",
      "890      0            370376   7.7500  ...           1      False        True   \n",
      "\n",
      "     Embarked_S     AgeGroup  Age_child  Age_teen Age_young_adult  Age_adult  \\\n",
      "0          True  young_adult      False     False            True      False   \n",
      "1         False        adult      False     False           False       True   \n",
      "2          True  young_adult      False     False            True      False   \n",
      "3          True  young_adult      False     False            True      False   \n",
      "4          True  young_adult      False     False            True      False   \n",
      "..          ...          ...        ...       ...             ...        ...   \n",
      "886        True  young_adult      False     False            True      False   \n",
      "887        True  young_adult      False     False            True      False   \n",
      "888        True          NaN      False     False           False      False   \n",
      "889       False  young_adult      False     False            True      False   \n",
      "890       False  young_adult      False     False            True      False   \n",
      "\n",
      "     Age_senior  \n",
      "0         False  \n",
      "1         False  \n",
      "2         False  \n",
      "3         False  \n",
      "4         False  \n",
      "..          ...  \n",
      "886       False  \n",
      "887       False  \n",
      "888       False  \n",
      "889       False  \n",
      "890       False  \n",
      "\n",
      "[891 rows x 23 columns]>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "df['Sex_encoded'] = label_encoder.fit_transform(df['Sex'])\n",
    "print(\"encodage label Sex\")\n",
    "\n",
    "df_embarked_encoded = pd.get_dummies(df['Embarked'], prefix='Embarked')\n",
    "df = pd.concat([df, df_embarked_encoded], axis=1)\n",
    "print(\"encodage one-hot de Embarked\")\n",
    "print(\"colonnes ajoutees :\", ['Sex_encoded'] + list(df_embarked_encoded.columns))\n",
    "\n",
    "df['AgeGroup'] = pd.cut(\n",
    "    df['Age'],\n",
    "    bins=[0, 12, 18, 35, 60, 100],\n",
    "    labels=['child', 'teen', 'young_adult', 'adult', 'senior']\n",
    ")\n",
    "\n",
    "print(\"groupe 'AgeGroup'\")\n",
    "df_age_encoded = pd.get_dummies(df['AgeGroup'], prefix='Age')\n",
    "df = pd.concat([df, df_age_encoded], axis=1)\n",
    "\n",
    "print(\"encodage one-hot AgeGroup\")\n",
    "print(\"colonnes :\", list(df_age_encoded.columns))\n",
    "print(df.head)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e6e64bdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "temp moyenne:\n",
      "year\n",
      "2013     9.569589\n",
      "2014    11.091507\n",
      "2015    11.129863\n",
      "2016    10.419945\n",
      "2017    10.441918\n",
      "2018    11.389589\n",
      "2019    11.006575\n",
      "2020    11.004098\n",
      "2021     9.731781\n",
      "2022    11.367671\n",
      "Name: TMK, dtype: float64\n",
      "Extrait (standardisÃ©):         TMK       TXK  FM\n",
      "0  0.554982  0.418412 NaN\n",
      "1  0.453776  0.651419 NaN\n",
      "2  0.883903  0.895522 NaN\n",
      "3  0.706792  0.385125 NaN\n",
      "4  0.706792  0.429508 NaN\n",
      "Extrait (normalisÃ©):         TMK       TXK  FM\n",
      "0  0.640351  0.618042 NaN\n",
      "1  0.622807  0.658349 NaN\n",
      "2  0.697368  0.700576 NaN\n",
      "3  0.666667  0.612284 NaN\n",
      "4  0.666667  0.619962 NaN\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "df = pd.read_csv(\"weatherdata.csv\", sep=\";\")\n",
    "\n",
    "# nttoyage\n",
    "df.columns = df.columns.str.strip()\n",
    "df = df.replace(-999, pd.NA)\n",
    "\n",
    "df[\"MESS_DATUM\"] = pd.to_datetime(df[\"MESS_DATUM\"], format=\"%Y%m%d\", errors=\"coerce\")\n",
    "\n",
    "colonnes_a_supprimer = [\"eor\", \"STATIONS_ID\", \"QN_3\", \"QN_4\", \"RSKF\", \"SHK_TAG\"]\n",
    "df = df.drop(columns=[col for col in colonnes_a_supprimer if col in df.columns])\n",
    "\n",
    "colonnes_numeriques_connues = [\n",
    "    \"FX\", \"FM\", \"RSK\", \"SDK\", \"NM\", \"VPM\", \"PM\",\n",
    "    \"TMK\", \"UPM\", \"TXK\", \"TNK\", \"TGK\"\n",
    "]\n",
    "colonnes_presentes = [col for col in colonnes_numeriques_connues if col in df.columns]\n",
    "\n",
    "for col in colonnes_presentes:\n",
    "    df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "\n",
    "df = df.dropna(subset=[\"MESS_DATUM\", \"TMK\"])\n",
    "df[\"year\"] = df[\"MESS_DATUM\"].dt.year\n",
    "\n",
    "\n",
    "mean_temp_by_year = df.groupby(\"year\")[\"TMK\"].mean()\n",
    "print(\"temp moyenne:\")\n",
    "print(mean_temp_by_year.tail(10))\n",
    "def cap_outliers(df, column):\n",
    "    Q1 = df[column].quantile(0.25)\n",
    "    Q3 = df[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    seuil_bas = Q1 - 1.5 * IQR\n",
    "    seuil_haut = Q3 + 1.5 * IQR\n",
    "    df[column] = df[column].clip(seuil_bas, seuil_haut)\n",
    "\n",
    "for col in [\"TXK\", \"TMK\"]:\n",
    "    if col in df.columns:\n",
    "        cap_outliers(df, col)\n",
    "\n",
    "colonnes_scaling = [col for col in [\"TMK\", \"TXK\", \"FM\"] if col in df.columns]\n",
    "\n",
    "scaler_std = StandardScaler()\n",
    "scaler_norm = MinMaxScaler()\n",
    "\n",
    "df_std = df[colonnes_scaling].copy()\n",
    "df_norm = df[colonnes_scaling].copy()\n",
    "\n",
    "df_std[colonnes_scaling] = scaler_std.fit_transform(df_std[colonnes_scaling])\n",
    "df_norm[colonnes_scaling] = scaler_norm.fit_transform(df_norm[colonnes_scaling])\n",
    "print(\"Extrait (standardisÃ©):\", df_std.head())\n",
    "print(\"Extrait (normalisÃ©):\", df_norm.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
