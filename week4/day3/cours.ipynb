{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70de71a1",
   "metadata": {},
   "source": [
    "🧠 Feature Engineering — Fiche de Révision\n",
    "📌 Définition\n",
    "\n",
    "Le Feature Engineering consiste à transformer les données brutes pour extraire des variables (features) plus pertinentes et plus informatives pour un modèle ML. Cela revient à \"donner des super-pouvoirs\" à ton modèle en le guidant vers les bons signaux.\n",
    "\n",
    "Exemple : Créer une variable \"Surface Totale\" à partir de plusieurs surfaces de pièces pour un modèle de prédiction de prix de maison.\n",
    "🎯 Pourquoi c’est important ?\n",
    "\n",
    "    Une bonne feature > un modèle complexe mal alimenté\n",
    "\n",
    "    C’est l'étape qui permet aux algorithmes de capter les patterns pertinents.\n",
    "\n",
    "    Elle impacte fortement la performance, la précision, la robustesse du modèle.\n",
    "\n",
    "🛠️ Techniques classiques\n",
    "1. Imputation (Traitement des valeurs manquantes)\n",
    "\n",
    "    Moyenne : df[\"col\"].fillna(df[\"col\"].mean())\n",
    "\n",
    "    Valeur la plus fréquente : df[\"col\"].fillna(df[\"col\"].value_counts().idxmax())\n",
    "\n",
    "    Zéro : df.fillna(0)\n",
    "\n",
    "2. Gestion des Outliers\n",
    "\n",
    "    Suppression (risqué si dataset petit)\n",
    "\n",
    "    Remplacement (imputation après détection)\n",
    "\n",
    "    Capping (ex: limiter à P1/P99)\n",
    "\n",
    "    Discrétisation : découper les données continues en intervalles (binning)\n",
    "\n",
    "3. Encodage des variables catégorielles (One-hot encoding)\n",
    "\n",
    "Transforme chaque catégorie d’une variable en colonne binaire (0/1).\n",
    "Utilisé pour éviter les biais d'ordre implicite (problème de label encoding).\n",
    "\n",
    "pd.get_dummies(df, columns=[\"Couleur\"], prefix=[\"Color\"])\n",
    "\n",
    "✅ Utile pour tous les modèles qui nécessitent des entrées numériques\n",
    "✅ Préserve l’indépendance des catégories\n",
    "✅ Évite d’introduire une fausse hiérarchie entre les valeurs\n",
    "❓ Mini Quiz\n",
    "\n",
    "Quel est l’objectif principal du one-hot encoding ?\n",
    "✅ Représenter les variables catégorielles sous forme de colonnes binaires."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0180f1ad",
   "metadata": {},
   "source": [
    "🔍 Modèles de Classification — Fiche de Révision\n",
    "🍏 Exemple utilisé :\n",
    "\n",
    "Un dataset de fruits avec deux features : Poids et Couleur\n",
    "\n",
    "X = df[['Poids (g)', 'Couleur (1=Rouge, 0=Orange)']]\n",
    "y = df['Fruit']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "🌲 Random Forest\n",
    "🧠 Idée\n",
    "\n",
    "Un ensemble d’arbres de décision entraînés sur des sous-échantillons du dataset → vote majoritaire.\n",
    "✅ Avantages\n",
    "\n",
    "    Rapide, robuste, peu sensible à l’overfitting\n",
    "\n",
    "    Gère les données manquantes et les features non normalisées\n",
    "\n",
    "    Fonctionne bien avec beaucoup de features\n",
    "\n",
    "📦 Exemple\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "accuracy_score(y_test, model.predict(X_test))\n",
    "\n",
    "🔁 Gradient Boosting\n",
    "🧠 Idée\n",
    "\n",
    "Construction séquentielle d'arbres où chaque nouveau arbre corrige les erreurs du précédent.\n",
    "✅ Avantages\n",
    "\n",
    "    Très précis\n",
    "\n",
    "    Réduit le biais\n",
    "\n",
    "    Bon sur les petits datasets bien préparés\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "model = GradientBoostingClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "⚡ XGBoost (Extreme Gradient Boosting)\n",
    "🧠 Idée\n",
    "\n",
    "Version optimisée du Gradient Boosting, avec régularisation, gestion des valeurs manquantes, parallélisme, etc.\n",
    "✅ Avantages\n",
    "\n",
    "    Ultra performant\n",
    "\n",
    "    Efficace pour données structurées\n",
    "\n",
    "    Favori dans les compétitions Kaggle\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "model = XGBClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "✴️ Support Vector Classifier (SVC)\n",
    "🧠 Idée\n",
    "\n",
    "Cherche la meilleure frontière de décision (maximiser la marge entre classes). Peut être non-linéaire avec les kernels.\n",
    "📌 Hyperparamètres clés\n",
    "\n",
    "    C (régularisation)\n",
    "\n",
    "    kernel (linear, rbf, poly)\n",
    "\n",
    "    gamma (influence d’un point d’apprentissage)\n",
    "\n",
    "✅ Avantages\n",
    "\n",
    "    Excellente performance si les données sont bien préparées\n",
    "\n",
    "    Efficace en haute dimension\n",
    "\n",
    "    Sensible au scaling !\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "model = SVC()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc6e642",
   "metadata": {},
   "source": [
    "Voici la Partie 3 : Hyperparameter Tuning — Fiche de Révision, centrée sur les définitions, méthodes, et exemples pratiques à retenir.\n",
    "🧪 Hyperparameter Tuning — Fiche de Révision\n",
    "📌 Définition\n",
    "\n",
    "Les hyperparamètres sont des paramètres fixés avant l’entraînement. Contrairement aux paramètres appris (comme les poids dans une régression), ils contrôlent le comportement de l’apprentissage.\n",
    "🔧 Exemples d’hyperparamètres\n",
    "🔷 Support Vector Machine (SVC)\n",
    "\n",
    "    C : contrôle la régularisation (trade-off entre marge large et erreurs)\n",
    "\n",
    "    kernel : fonction de transformation (lineaire, rbf, poly, etc.)\n",
    "\n",
    "    gamma : influence des points d’apprentissage (petit = global, grand = local)\n",
    "\n",
    "🔷 XGBoost\n",
    "\n",
    "    learning_rate : taux d’apprentissage\n",
    "\n",
    "    n_estimators : nombre d’arbres\n",
    "\n",
    "    max_depth : profondeur maximale\n",
    "\n",
    "    min_child_weight : minimum de poids par noeud\n",
    "\n",
    "    subsample : proportion d’échantillons utilisée\n",
    "\n",
    "🧭 Méthodes de Tuning\n",
    "🔍 GridSearchCV\n",
    "\n",
    "🧠 Approche exhaustive : teste toutes les combinaisons possibles\n",
    "📌 Coût élevé si la grille est grande\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {'C': [0.1, 1, 10]}\n",
    "grid = GridSearchCV(SVC(), param_grid, cv=5)\n",
    "grid.fit(X, y)\n",
    "print(grid.best_params_)\n",
    "\n",
    "🎲 RandomizedSearchCV\n",
    "\n",
    "🧠 Approche plus rapide : teste un sous-ensemble aléatoire de combinaisons\n",
    "✅ Plus scalable sur gros espaces d’hyperparamètres\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint\n",
    "\n",
    "param_dist = {\n",
    "    \"max_depth\": [None, 10, 20],\n",
    "    \"min_samples_split\": randint(2, 10)\n",
    "}\n",
    "search = RandomizedSearchCV(RandomForestClassifier(), param_dist, cv=5)\n",
    "search.fit(X, y)\n",
    "print(search.best_params_)\n",
    "\n",
    "🧠 Résumé Comparatif\n",
    "Méthode\tStratégie\tVitesse\tPrécision potentielle\n",
    "GridSearchCV\tExhaustive\tLente\tHaute si espace réduit\n",
    "RandomizedSearchCV\tAléatoire (sampling)\tRapide\tTrès bonne si bien configurée\n",
    "💪 Exercice à compléter\n",
    "\n",
    "Remplis les lignes manquantes pour entraîner un RandomForest avec RandomizedSearchCV :\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "param_dist = {\n",
    "    \"n_estimators\": [10, 50, 100],\n",
    "    \"max_depth\": [None, 10, 20],\n",
    "    \"min_samples_split\": [2, 5],\n",
    "    \"min_samples_leaf\": [1, 2],\n",
    "    \"max_features\": [\"auto\", \"sqrt\"]\n",
    "}\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "rf_cv = RandomizedSearchCV(rf, param_dist, cv=5)\n",
    "rf_cv.fit(X, y)\n",
    "\n",
    "print(\"Tuned Parameters:\", rf_cv.best_params_)\n",
    "print(\"Best score:\", rf_cv.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "399b9f12",
   "metadata": {},
   "source": [
    "🔄 Cross-Validation (CV) — Fiche de Révision\n",
    "📌 Définition\n",
    "\n",
    "Le Cross-Validation est une technique d’évaluation qui consiste à diviser les données en plusieurs sous-ensembles (folds) pour entraîner et tester un modèle de façon plus robuste et réaliste que le simple train/test split.\n",
    "🎯 Pourquoi c’est crucial ?\n",
    "\n",
    "    ✅ Mieux estimer la performance généralisable (non biaisée)\n",
    "\n",
    "    ✅ Réduire la variance d’évaluation\n",
    "\n",
    "    ✅ Éviter le surapprentissage (overfitting) à un seul jeu de test\n",
    "\n",
    "    ✅ Évaluer différents modèles / hyperparamètres de façon équitable\n",
    "\n",
    "📦 Méthode la plus courante : K-Fold Cross-Validation\n",
    "🔧 Fonctionnement\n",
    "\n",
    "    Diviser les données en k groupes (folds) égaux\n",
    "\n",
    "    Pour chaque fold :\n",
    "\n",
    "        Entraîner le modèle sur k-1 folds\n",
    "\n",
    "        Tester sur le fold restant\n",
    "\n",
    "    Répéter k fois\n",
    "\n",
    "    Calculer la moyenne des scores\n",
    "\n",
    "📌 Exemple : k=5\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "scores = cross_val_score(model, X, y, cv=5)\n",
    "print(\"Scores pour chaque fold :\", scores)\n",
    "print(\"Score moyen :\", scores.mean())\n",
    "\n",
    "⚠️ Attention\n",
    "\n",
    "    CV doit être utilisé avant le test final, sinon risque de fuite de données.\n",
    "\n",
    "    Pour un tuning fiable : intégrer CV dans le GridSearch ou RandomizedSearch.\n",
    "\n",
    "🧠 Bonus : Stratified K-Fold\n",
    "\n",
    "Utilisé pour les problèmes de classification :\n",
    "\n",
    "    Garantit que chaque fold contient la même proportion de classes\n",
    "\n",
    "    Evite un déséquilibre classe majoritaire / minoritaire\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5)\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    print(\"Fold:\", train_index, test_index)\n",
    "\n",
    "🔍 À retenir pour l'entretien ou l’examen :\n",
    "\n",
    "    \"J’utilise toujours le cross-validation pour m’assurer que la performance du modèle est stable et généralisable. J’intègre généralement une K-Fold CV avec k=5 ou 10 dans mes GridSearch pour le tuning.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac2d8a96",
   "metadata": {},
   "source": [
    "⚔️ Comparaison de Modèles avec Cross-Validation\n",
    "\n",
    "On va comparer trois modèles sur un même dataset (classification binaire) :\n",
    "\n",
    "    RandomForest\n",
    "\n",
    "    GradientBoosting\n",
    "\n",
    "    SVC\n",
    "\n",
    "🧪 Code complet :\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Générer un dataset artificiel\n",
    "X, y = make_classification(n_samples=1000, n_features=20, n_informative=10, n_classes=2, random_state=42)\n",
    "\n",
    "# Définir les modèles\n",
    "models = {\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(),\n",
    "    \"SVC\": SVC()\n",
    "}\n",
    "\n",
    "# Appliquer Cross-Validation et comparer les performances\n",
    "for name, model in models.items():\n",
    "    scores = cross_val_score(model, X, y, cv=5)\n",
    "    print(f\"{name} - Accuracy moyenne : {scores.mean():.3f} (écart-type : {scores.std():.3f})\")\n",
    "\n",
    "💪 Exercice corrigé\n",
    "\n",
    "Objectif : Compléter un comparatif entre LogisticRegression et RandomForestClassifier sur un dataset simulé, avec CV à 10 folds.\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=10, n_informative=5, random_state=42)\n",
    "\n",
    "# Modèles\n",
    "logreg = LogisticRegression()\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "# CV sur 10 folds\n",
    "logreg_scores = cross_val_score(logreg, X, y, cv=10)\n",
    "rf_scores = cross_val_score(rf, X, y, cv=10)\n",
    "\n",
    "# Résultats\n",
    "print(f\"LogisticRegression - Moyenne : {logreg_scores.mean():.3f}\")\n",
    "print(f\"RandomForest - Moyenne : {rf_scores.mean():.3f}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
