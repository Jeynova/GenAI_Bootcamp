{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2cf4272c",
   "metadata": {},
   "source": [
    "\n",
    "Pinecone Serverless Reranking\n",
    "\n",
    "Last Updated: April 27th, 2025\n",
    "\n",
    "Daily Challenge: Pinecone Serverless Reranking in Action\n",
    "\n",
    "\n",
    "Why are we doing this?\n",
    "\n",
    "Reranking models boost search relevance by assigning similarity scores between a query and documents, then reordering results so the most pertinent information appears first. In contexts like healthcare, this helps clinicians quickly access the most critical clinical notes.\n",
    "\n",
    "\n",
    "Task Overview & Detailed Explanations\n",
    "\n",
    "Below is a skeleton pipeline. Each numbered item is an action you must complete. After every instruction, you'll find a clear explanation of what to do and why it's important. Whenever you see ..., replace it with the appropriate code or value, using the hint for guidance.\n",
    "\n",
    "\n",
    "Part 1: Load Documents & Execute Reranking Model\n",
    "\n",
    "\n",
    "\n",
    "1. Install Pinecone libraries\n",
    "\n",
    "\n",
    "pip install pinecone==6.0.1 pinecone-notebooks\n",
    "\n",
    "\n",
    "    What to do: Run this command in your terminal or notebook to install the Pinecone client library and the notebook helper package.\n",
    "    Why: You'll need the client package to interact with Pinecone's API and the notebook helper to simplify authentication in environments like Colab.\n",
    "\n",
    "\n",
    "2. Authenticate with Pinecone\n",
    "\n",
    "\n",
    "import os\n",
    "if not os.environ.get(\"PINECONE_API_KEY\"):\n",
    "   from pinecone_notebooks.colab import Authenticate\n",
    "   Authenticate()\n",
    "\n",
    "\n",
    "    What to do: Check if your environment has the PINECONE_API_KEY. If not, call Authenticate() to prompt for it.\n",
    "    Why: Securely providing your API key lets the client connect to your Pinecone project without hard-coding secrets in your script.\n",
    "\n",
    "\n",
    "3. Instantiate the Pinecone client\n",
    "\n",
    "\n",
    "from pinecone import Pinecone\n",
    "api_key = os.environ[\"PINECONE_API_KEY\"]\n",
    "environment = \"...\"  # e.g., \"us-west1-gcp\"\n",
    "pc = Pinecone(api_key=api_key, environment=environment)\n",
    "\n",
    "\n",
    "    What to do: Fill in your Pinecone project's environment string (found in your Pinecone dashboard) in place of .... Then create a Pinecone client instance.\n",
    "    Why: The client (pc) is your entry point for all Pinecone operations—creating indexes, querying, and reranking.\n",
    "\n",
    "\n",
    "4. Define your query & documents\n",
    "\n",
    "\n",
    "query = \"Tell me about Apple's products\"\n",
    "documents = [\n",
    "   ...  # Provide five text strings: some about the fruit, some about the company\n",
    "]\n",
    "\n",
    "\n",
    "    What to do: Replace ... with a list of five example sentences that include both references to the fruit “apple” and the company “Apple Inc.”.\n",
    "    Why: You need a small set of documents to test the reranker's ability to distinguish between different contexts of the same word.\n",
    "\n",
    "\n",
    "5. Call the reranker\n",
    "\n",
    "\n",
    "from pinecone import RerankModel\n",
    "reranked = pc.inference.rerank(\n",
    "   model=\"bge-reranker-v2-m3\",\n",
    "   query=query,\n",
    "   documents=[{\"id\": str(i), \"text\": doc} for i, doc in enumerate(documents)],\n",
    "   top_n=...  # e.g., 3\n",
    ")\n",
    "\n",
    "\n",
    "    What to do: Fill in top_n with how many top results you want returned (e.g., 3).\n",
    "    Why: top_n limits the number of reranked results, so you only retrieve the most relevant documents.\n",
    "\n",
    "\n",
    "6. Inspect reranked results\n",
    "\n",
    "\n",
    "def show_reranked(query, matches):\n",
    "   print(f\"Query: {query}\")\n",
    "   for i, m in enumerate(matches):\n",
    "       ...  # Print the position (i+1), m.score, and m.document.text\n",
    "show_reranked(query, reranked.matches)\n",
    "\n",
    "\n",
    "    What to do: Replace ... with code that prints out the rank (i+1), the similarity score m.score, and the document text m.document.text.\n",
    "    Why: Seeing these values demonstrates how the reranker orders documents and what scores it assigns.\n",
    "\n",
    "\n",
    "Part 2: Setup a Serverless Index for Medical Notes\n",
    "\n",
    "1. Install data & model libraries\n",
    "\n",
    "\n",
    "pip install pandas torch transformers\n",
    "\n",
    "\n",
    "    What to do: Install pandas for data manipulation, torch for model inference, and transformers for loading embedding models.\n",
    "    Why: You'll use these libraries to load, embed, and manipulate medical note data.\n",
    "\n",
    "\n",
    "2. Import modules & define environment settings\n",
    "\n",
    "\n",
    "import os, time, pandas as pd, torch\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "\n",
    "cloud = \"...\"        # e.g., \"aws\"\n",
    "region = \"...\"       # e.g., \"us-east-1\"\n",
    "spec = ServerlessSpec(cpu=..., memory_gb=...)\n",
    "index_name = \"pinecone-reranker\"\n",
    "\n",
    "pc = Pinecone(api_key=os.environ[\"PINECONE_API_KEY\"], environment=f\"{cloud}-{region}\")\n",
    "\n",
    "\n",
    "    What to do: Fill in cloud and region with your Pinecone project's deployment environment. Choose CPU and memory values in ServerlessSpec.\n",
    "    Why: You're configuring a serverless index tailored to your resource requirements and connecting the client in the proper cloud region.\n",
    "\n",
    "\n",
    "3. Create or recreate the index\n",
    "\n",
    "\n",
    "if pc.has_index(index_name):\n",
    "   pc.delete_index(index_name)\n",
    "pc.create_index(\n",
    "   name=index_name,\n",
    "   dimension=...,           # must match embedding vector size\n",
    "   serverless_config=spec\n",
    ")\n",
    "\n",
    "\n",
    "    What to do: Set dimension equal to your embedding model's output size (e.g., 384).\n",
    "    Why: The index's dimension must match the embedding vectors you'll insert, otherwise upserts will fail.\n",
    "\n",
    "\n",
    "Part 3: Load the Sample Data\n",
    "\n",
    "1. Download & read JSONL\n",
    "\n",
    "\n",
    "import requests, tempfile\n",
    "\n",
    "with tempfile.TemporaryDirectory() as tmpdir:\n",
    "   file_path = os.path.join(tmpdir, \"sample_notes_data.jsonl\")\n",
    "   url = \"...\"  # raw GitHub URL to JSONL file\n",
    "   resp = requests.get(url)\n",
    "   resp.raise_for_status()\n",
    "   open(file_path, \"wb\").write(resp.content)\n",
    "   df = pd.read_json(file_path, orient='records', lines=True)\n",
    "\n",
    "\n",
    "    What to do: Insert the raw URL in place of ... to download the sample medical notes.\n",
    "    Why: You need a DataFrame of medical notes (with embeddings already available) to index and test queries.\n",
    "\n",
    "\n",
    "2. Preview the DataFrame\n",
    "\n",
    "\n",
    "print(df.head())\n",
    "\n",
    "\n",
    "    What to do: Run this to view the first few rows of the DataFrame.\n",
    "    Why: Ensures you have the right columns (e.g., id, embedding, metadata) before upserting.\n",
    "\n",
    "\n",
    "Part 4: Upsert Data into the Index\n",
    "\n",
    "1. Instantiate index client & upsert\n",
    "\n",
    "\n",
    "index = pc.Index(index_name)\n",
    "index.upsert_from_dataframe(df)\n",
    "\n",
    "\n",
    "    What to do: Create an Index object and call upsert_from_dataframe.\n",
    "    Why: This pushes all your note embeddings and metadata into Pinecone for later queries.\n",
    "\n",
    "\n",
    "2. Wait for availability\n",
    "\n",
    "\n",
    "def is_ready(idx):\n",
    "   stats = idx.describe_index_stats()\n",
    "   return stats.total_vector_count > 0\n",
    "\n",
    "while not is_ready(index):\n",
    "   time.sleep(5)\n",
    "print(index.describe_index_stats())\n",
    "\n",
    "\n",
    "    What to do: Poll until total_vector_count is greater than zero.\n",
    "    Why: Ensures that upserted vectors are fully indexed before you attempt to query.\n",
    "\n",
    "\n",
    "Part 5: Query & Embedding Function\n",
    "\n",
    "1. Define your embedding function\n",
    "\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "def get_embedding(text):\n",
    "   model = SentenceTransformer(\"...\")  # e.g., \"all-MiniLM-L6-v2\"\n",
    "   return model.encode(text)\n",
    "\n",
    "\n",
    "    What to do: Provide the name of the sentence-transformer model you plan to use in place of ....\n",
    "    Why: Converts incoming queries into the same vector space as your indexed notes.\n",
    "\n",
    "\n",
    "2. Run a semantic search query\n",
    "\n",
    "\n",
    "question = \"...\"  # e.g., \"what if my patient has leg pain\"\n",
    "emb = get_embedding(question)\n",
    "results = index.query(vector=emb, top_k=..., include_metadata=True)\n",
    "matches = sorted(results.matches, key=lambda m: m.score, reverse=True)\n",
    "\n",
    "\n",
    "    What to do: Replace question, set top_k for number of results (e.g., 5).\n",
    "    Why: Retrieves the most semantically similar notes from the index based on your clinical query.\n",
    "\n",
    "\n",
    "Part 6: Display & Rerank Clinical Notes\n",
    "\n",
    "1. Display initial search results\n",
    "\n",
    "\n",
    "def show_results(q, matches):\n",
    "   print(f\"Question: {q}\")\n",
    "   for i, m in enumerate(matches):\n",
    "       ...  # print i+1, m.id, m.score, m.metadata\n",
    "show_results(question, matches)\n",
    "\n",
    "\n",
    "    What to do: Fill in the print statement to show rank, vector ID, similarity score, and metadata.\n",
    "    Why: Helps you see which notes were initially considered most relevant.\n",
    "\n",
    "\n",
    "2. Prepare documents for reranking\n",
    "\n",
    "\n",
    "rerank_docs = [\n",
    "   {\"id\": m.id, \"reranking_field\": \"; \".join([f\"{k}: {v}\" for k, v in m.metadata.items()])}\n",
    "   for m in matches\n",
    "]\n",
    "rerank_query = \"...\"  # e.g., a more specific clinical question\n",
    "\n",
    "\n",
    "    What to do: Set rerank_query to a refined question that tests finer distinctions (e.g., focusing on a procedure or symptom).\n",
    "    Why: Constructs a field summarizing each note's metadata for the reranker to use when rescoring.\n",
    "\n",
    "\n",
    "3. Execute serverless reranking\n",
    "\n",
    "\n",
    "reranked = pc.inference.rerank(\n",
    "   model=\"bge-reranker-v2-m3\",\n",
    "   query=rerank_query,\n",
    "   documents=rerank_docs,\n",
    "   rank_fields=[\"reranking_field\"],\n",
    "   top_n=...  # number of top reranked notes to view\n",
    ")\n",
    "\n",
    "\n",
    "    What to do: Choose top_n to specify how many reranked results you need.\n",
    "    Why: Reranking uses the refined query and metadata field to reorder notes by their new relevance scores.\n",
    "\n",
    "\n",
    "4. Show reranked results\n",
    "\n",
    "\n",
    "def show_reranked(q, matches):\n",
    "   print(f\"Refined Query: {q}\")\n",
    "   for i, m in enumerate(matches):\n",
    "       ...  # print i+1, m.document.id, m.score, m.document.reranking_field\n",
    "show_reranked(rerank_query, reranked.matches)\n",
    "\n",
    "\n",
    "    What to do: Complete the print logic to display each reranked note's rank, ID, score, and the reranking_field.\n",
    "    Why: Allows you to compare how the reranker improves result ordering against the original search.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "413b6494",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os, requests, tempfile, time, pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from pinecone import Pinecone, ServerlessSpec, RerankModel\n",
    "\n",
    "# chargement de la clé API\n",
    "load_dotenv()\n",
    "api_key = os.environ.get(\"API_PINECONE\")\n",
    "if not api_key:\n",
    "    raise ValueError(\"API_PINECONE introuvable dans .env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0451852c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Création de l’index 'medical-notes-index' avec dimension 384\n"
     ]
    }
   ],
   "source": [
    "# instanciation du client Pinecone\n",
    "cloud = \"aws\"\n",
    "region = \"us-east-1\"\n",
    "environment = f\"{cloud}-{region}\"\n",
    "pc = Pinecone(api_key=api_key, environment=environment)\n",
    "\n",
    "# instanciation du client Pinecone\n",
    "cloud = \"aws\"\n",
    "region = \"us-east-1\"\n",
    "environment = f\"{cloud}-{region}\"\n",
    "pc = Pinecone(api_key=api_key, environment=environment)\n",
    "\n",
    "# création de l'index serverless\n",
    "index_name = \"medical-notes-index\"\n",
    "dim = 384\n",
    "\n",
    "spec = ServerlessSpec(cloud=cloud, region=region)\n",
    "\n",
    "if pc.has_index(index_name):\n",
    "    pc.delete_index(index_name)\n",
    "pc.create_index(name=index_name, dimension=dim, spec=spec)\n",
    "print(f\"Création de l'index '{index_name}' avec dimension {dim}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7e6d3a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aperçu du DataFrame :\n",
      "     id                                             values  \\\n",
      "0  P011  [-0.2027486265, 0.2769146562, -0.1509393603, 0...   \n",
      "1  P001  [0.1842793673, 0.4459365904, -0.0770567134, 0....   \n",
      "2  P002  [-0.2040648609, -0.1739618927, -0.2897160649, ...   \n",
      "3  P003  [0.1889383644, 0.2924542725, -0.2335938066, -0...   \n",
      "4  P004  [-0.12171068040000001, 0.1674752235, -0.231888...   \n",
      "\n",
      "                                            metadata  \n",
      "0  {'advice': 'rest, hydrate', 'symptoms': 'heada...  \n",
      "1  {'tests': 'EKG, stress test', 'symptoms': 'che...  \n",
      "2  {'HbA1c': '7.2', 'condition': 'diabetes', 'med...  \n",
      "3  {'symptoms': 'cough, wheezing', 'diagnosis': '...  \n",
      "4  {'referral': 'dermatology', 'condition': 'susp...  \n"
     ]
    }
   ],
   "source": [
    "# téléchargement et chargement des données JSONL\n",
    "url = \"https://raw.githubusercontent.com/pinecone-io/examples/refs/heads/master/docs/data/sample_notes_data.jsonl\"\n",
    "with tempfile.TemporaryDirectory() as tmpdir:\n",
    "    file_path = os.path.join(tmpdir, \"sample_notes_data.jsonl\")\n",
    "    resp = requests.get(url)\n",
    "    resp.raise_for_status()\n",
    "    with open(file_path, \"wb\") as f:\n",
    "        f.write(resp.content)\n",
    "    df = pd.read_json(file_path, orient='records', lines=True)\n",
    "\n",
    "print(\"Aperçu du DataFrame :\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca9f713e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbd226b0cc104ba5b4d9ff7a8a837752",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sending upsert requests:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upsert en cours...\n",
      "En attente de l'index…\n",
      "En attente de l'index…\n",
      "En attente de l'index…\n",
      "En attente de l'index…\n",
      "En attente de l'index…\n",
      "En attente de l'index…\n",
      "En attente de l'index…\n",
      "En attente de l'index…\n",
      "En attente de l'index…\n",
      "Vecteurs insérés. Détail de l'index :\n",
      "{'dimension': 384,\n",
      " 'index_fullness': 0.0,\n",
      " 'metric': 'cosine',\n",
      " 'namespaces': {'': {'vector_count': 100}},\n",
      " 'total_vector_count': 100,\n",
      " 'vector_type': 'dense'}\n"
     ]
    }
   ],
   "source": [
    "# insertion dans l'index Pinecone\n",
    "index = pc.Index(index_name)\n",
    "index.upsert_from_dataframe(df)\n",
    "print(\"Upsert en cours...\")\n",
    "\n",
    "while True:\n",
    "    stats = index.describe_index_stats()\n",
    "    if stats.total_vector_count > 0:\n",
    "        break\n",
    "    print(\"En attente de l'index…\")\n",
    "    time.sleep(5)\n",
    "\n",
    "print(\"Vecteurs insérés. Détail de l'index :\")\n",
    "print(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e3192e24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Résultats brut de la recherche sémantique :\n",
      "1. id=P0100, score=0.5329, metadata={'advice': 'over-the-counter pain relief, stretching', 'symptoms': 'muscle pain'}\n",
      "2. id=P047, score=0.5078, metadata={'symptoms': 'back pain', 'treatment': 'physical therapy'}\n",
      "3. id=P095, score=0.5078, metadata={'symptoms': 'back pain', 'treatment': 'physical therapy'}\n",
      "4. id=P007, score=0.4539, metadata={'surgery': 'knee arthroscopy', 'symptoms': 'pain, swelling', 'treatment': 'physical therapy'}\n",
      "5. id=P092, score=0.4475, metadata={'condition': 'dehydration', 'treatment': 'IV fluids'}\n"
     ]
    }
   ],
   "source": [
    "# définition de la fonction d'embed pour la requête\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "def get_embedding(text):\n",
    "    return model.encode(text).tolist()\n",
    "\n",
    "# recherche sémantique\n",
    "question = \"What if my patient has leg pain?\"\n",
    "emb = get_embedding(question)\n",
    "res = index.query(vector=emb, top_k=5, include_metadata=True)\n",
    "matches = sorted(res.matches, key=lambda m: m.score, reverse=True)\n",
    "\n",
    "print(\"\\nRésultats brut de la recherche sémantique :\")\n",
    "for i, m in enumerate(matches, 1):\n",
    "    print(f\"{i}. id={m.id}, score={m.score:.4f}, metadata={m.metadata}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "344c1d7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Résultats après reranking :\n",
      "1. id=P007, score=0.0768, text=surgery: knee arthroscopy; symptoms: pain, swelling; treatment: physical therapy...\n",
      "2. id=P0100, score=0.0131, text=advice: over-the-counter pain relief, stretching; symptoms: muscle pain...\n",
      "3. id=P047, score=0.0065, text=symptoms: back pain; treatment: physical therapy...\n"
     ]
    }
   ],
   "source": [
    "# préparation des documents pour reranking\n",
    "rerank_docs = [\n",
    "    {\"id\": m.id, \"text\": \"; \".join(f\"{k}: {v}\" for k, v in (m.metadata or {}).items())}\n",
    "    for m in matches\n",
    "]\n",
    "\n",
    "rerank_query = \"Patient reports leg swelling and difficulty walking.\"\n",
    "\n",
    "# exécution du reranker avec les corrections\n",
    "try:\n",
    "    reranked = pc.inference.rerank(\n",
    "        model=\"bge-reranker-v2-m3\",\n",
    "        query=rerank_query,\n",
    "        documents=rerank_docs,\n",
    "        top_n=3,\n",
    "        return_documents=True,\n",
    "        parameters={\"truncate\": \"END\"}\n",
    "    )\n",
    "    if not reranked or not reranked.data:\n",
    "        raise ValueError(\"Le reranker n'a retourné aucun résultat.\")\n",
    "except Exception as e:\n",
    "    print(\"Erreur pendant le reranking :\", e)\n",
    "    exit()\n",
    "\n",
    "# affichage des résultats rerankés\n",
    "print(\"\\nRésultats après reranking :\")\n",
    "for i, item in enumerate(reranked.data, 1):\n",
    "    doc = item[\"document\"]\n",
    "    score = item[\"score\"]\n",
    "    text = doc.get(\"text\", \"\")\n",
    "    print(f\"{i}. id={doc['id']}, score={score:.4f}, text={text[:100]}...\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
